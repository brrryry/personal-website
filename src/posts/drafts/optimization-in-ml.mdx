---
title: "'Unhinged and Unconstrained': Optimization Techniques in Machine Learning"
date: "2025-11-03"
description: "We are traditionally taught about gradient descent in ML, but what about other ways?"
tags: ["ml"]
---

I'm currently halfway through my MA630 course (Optimization Methods) at Stevens, and it's been a blast.
I've learned about things that I've never even heard of before. \
\
Initially, I was thinking of writing a blog series for this class! The content is super dense and interesting.
However, if I do write a blog like that, I'd like to start off by combining some of the concepts I've learned so far with
my previous knowledge - machine learning. Hence, this post! \
\
**NOTE: This blog assumes that you have a background in vector calculus and linear algebra.** You don't necessarily have to know
too much about machine learning to follow along, but some familiarity would help!

<br />

## Background: Machine Learning
For the sake of this blog's length, I'm not going to go over all of machine learning. \
\
I will define machine learning as the process of training a model to make predictions based on data. The model itself
can be a bunch of different things - anything from a linear regression model (y=mx+b, predicts a continuous value)
to a neural network is valid. As long as the model makes predictions on something based on data, it's fair game. \
\
**All models have parameters**. These are the "knobs" that we can turn to change how the model behaves. In its simplest form,
a linear regression model has two parameters: m (slope) and b (y-intercept). A neural network has many more parameters - weights
and biases for each neuron in the network. \
\
The process of training a model involves finding the best parameters (weights) for the model such that it minimizes
some "loss function" - a function that measures error between the model's predictions and the actual values. \
\
For example, let's say we have a model that predicts whether or not an email is spam. Whether it uses logistic regression,
a decision tree, or a neural network, it doesn't really matter. The important part is the output: a prediction of spam or not spam.
To convert this prediction into a number, let's say we use 1 for spam and 0 for not spam. \
\
For something like this, we will use a loss function called "binary cross-entropy loss".
Given the "true label" y (1 for spam, 0 for not spam) and the predicted probability p (between 0 and 1),

<LatexWrapper content="L(y, p) = \left( y \log(p) + (1 - y) \log(1 - p) \right)" />

This function will increase as the predicted probability goes further away from the true label. From here,
we want to find a way to make this "loss value" as small as possible by making "p" as close to "y" as possible. \
\
This brings up an important question: where the heck did we find this loss function??? Why this one?

<br />

## Background: Convexity and its Importance
A lot of these loss functions are very popular - not just because they work well to predict error, 
but because they have a few important mathematical properties: convexity and differentiability. \
\
If you've taken a calculus class before, you probably know what convexity is.
A function is convex if, for any two points on the function, the line segment connecting those two points lies above
the function itself (also known as an epigraph). \
\
This can also be defined in mathetmatical terms.

<LatexWrapper content="f(\theta x_1 + (1 - \theta) x_2) \leq \theta f(x_1) + (1 - \theta) f(x_2) \quad \forall x_1, x_2 \text{ and } \theta \in [0, 1]" />

This property is super important in optimization because it guarantees that any **local** minimum value of a convex function is 
also a **global** minimum value. This means that if we find a point where the function's slope is zero (a local minimum),
we can be sure that this point is the absolute lowest point on the function. \
\
Because of this, convex functions are much easier to optimize. We know a lot more about their behavior, and we can use techniques like gradient descent!

<br />

## What is Gradient Descent?
I'm sure that you've learned about critical points before to find minima and maxima of functions. You take the derivative of the function,
set it to zero and solve for the variable. Why don't we just do that? \
\
Well...this method works for simple functions with one or two variables. But what about functions with hundreeds? Thousands? \
\
These kinds of operations are extremely expensive to compute. We need a more efficient way to find minima of these functions. \
\
Enter, gradient descent! Gradient Descent (which I will notate as GD) is an iterative optimization algorithm to find minima. 
Instead of finding a closed form solution, GD takes small steps in the direction of the steepest descent to find a minimum. \
\
(As a note, the steepest descent is given by the negative of the gradient of the function at a given point.) \
\
Going back to why convexity is important - it gives us a function that's almost like a bowl. If we start at any point on the bowl,
we can follow the steepest descent to reach the bottom of the bowl (the global minimum). \
\
Here's what the update rule for Gradient Descent looks like! 
<BlogList>
<li>Initialize parameters (weights) randomly</li>
<li>Compute the gradient of the loss function with respect to the parameters. Sometimes, this can require backpropagation (which is a whole separate problem).</li>
<li>Update the parameters by taking a step in the direction of the negative gradient.</li>
<li>Repeat steps 2 and 3 until convergence (when the change in loss is below a certain threshold or after a set number of iterations).</li>
</BlogList>

The update rule can be summarized mathematically as:
<LatexWrapper content="\theta = \theta - \alpha \nabla L(\theta)" />
where θ represents the parameters, α is the learning rate (step size), and ∇L(θ) is the gradient of the loss function with respect to the parameters. \
\
The learning rate controls how much of a "step" we take in the direction of the negative gradient! 

<br />

## Other Optimization Techniques?
Alright, so now we know how to optimize functions using gradient descent. In fact, gradient descent is the most commonly used optimization technique
in machine learning! Because of this, most machine learning classes only cover gradient descent and its variants (stochastic gradient descent, mini-batch gradient descent, etc). 
However, let's look at some other optimization techniques - the ones that aren't common - and understand how they work and why they aren't used as often. \
\
Heck, we can even consider implementing non-convex loss functions now. 

<br />

### 1. Genetic Algorithms
