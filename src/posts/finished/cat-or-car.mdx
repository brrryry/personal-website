---
title: "Cat or Car?"
date: "2024-08-06"
description: "Demo for a little project that I made using a convolutional neural network!"
tags: ["coding", "ml"]
---

## Credit Where It Is Due

<a
  href="https://machinelearningmastery.com/how-to-develop-a-convolutional-neural-network-to-classify-photos-of-dogs-and-cats/"
  target="_blank"
>Cat vs Dog Machine Learning Project
</a> - basically my go-to tutorial

<br />
## Link to the project: <a href="/projects/cat-or-car">here</a>
Demo pics at the end :)
<br />

**Warning: this is not a tutorial.** I am sorry for the lack of explanation, but I will make real
tutorials with good explanations at another time. \
\
So...I'm gonna be taking a machine learning class soon (<a href="https://online.stevens.edu/course/cs-559-machine-learning-fundamentals-and-applications/" target="_blank">CS559</a>).

<br />

I wanted to make something machine learning-related so that I'm prepared to take on the course material.
Usually, I tend to do this in order to get ahead (since I'm very bad at learning things in real time).\
Therefore, I proudly present...

<br />

## "Cat or Car?"

The idea came from...memes on the internet (I'mma keep it real). However, I was able to put my
machine learning concepts to the test. This blog will consist of a concept breakdown, a coding speedrun
and...some other things.

<br />

## Concept Breakdown

Let's start from the beginning. What is machine learning? \
\
Machine learning is a subsection of artificial intelligence that focuses on using random numbers
and mathematical functions to generate some kind "bigger function". For example, let's say that we
want to input an image and have our program tell us if it is a cat or a car. In order to do so, this image
is inputted into this "bigger function" - a black box that is unknown to the user. This black box - realistically -
is just a bunch of random numbers and mathematical functions. That's all that most of these "machine learning models"
are. \
\
This project uses what's called a **neural network** - a subcategory of machine learning models. Neural networks specifically
use interconnected "nodes" to produce an output. An image is provided below.

<BlogImage
  src="https://www.mathworks.com/content/dam/mathworks/mathworks-dot-com/images/responsive/supporting/discovery/new-machine-learning-models-disc-page-neural-network.jpg"
  alt="Image of a neural network concept diagram"
  caption="A neural network concept diagram"
  source="https://www.mathworks.com/discovery/machine-learning-models.html"
/>

You can imagine that each circle is a node that contains a number and a weight. A column of circles is known as a **layer**, and outputs are
calculated layer by layer. Each layer's nodes have connections to nodes of the next layer (in this diagram, those would be the lines). The layer-by-layer
propagation is what's known as **forward propagation**.
However, the brilliance of the neural network is the effect that the output has **on the network**. Once an output is created on the last layer,
there is some math that is done to "optimize" the random numbers in all of the layers. This is known as **backward propagation**. As more information is put through the neural network,
the nodes will optimize themselves to become better at their job. Cool, right?\
\
Now, let's get a bit more specific. In this project, I used a **supervised learning model**. This basically tells you the way that the backwards propagation works in the model.
"Supervised" means that the neural network's backward propagation is based on predetermined outputs. In this example, I gave the neural network some pictures of cats and cars, it
tried to predict what it was, and then **I gave it the actual answer**. From there, the neural network can take the difference between my answer and its answer and optimize itself accordingly.
There are many different types of learning models, but they get more complicated...you can do your own research on that. \
\
Okay, here's one last specification - this project uses a **convolutional neural network**. This just means that the
neural network focuses on computer vision (2D/3D images or videos). \
In summary, this project uses a **supervised learning model** on a **convolutional neural network**. Lots of fancy words,
but the meaning is not too complicated. \
\
In this project's convolutional neural network, there are only two interesting types of layers that we need to know about: convolutional layers and max pooling layers.
In order to explain these layers, I will assume that you have some knowledge in how images are stored in a computer (RGB colors, pixel values, etc.).
In a convolutional layer, there exists a **"kernel"** - a small matrix of numbers. This kernel is then multiplied repeatedly over the image as if it is
"slid" across. An image is provided below for an example. There are more complex types of convolution, but...that's too much to cover here.

<BlogImage
  src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*32zCSTBi3giSApz1oQV-zA.gif"
  alt="GIF of convolutional layer calculations"
  caption="A convolutional layer"
  source="https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9"
/>

A max pooling layer essentially repeatedly takes a chunk of pixels in an image and finds the "maximum value". This is then saved in a new feature map.
An image is provided below for an example.

<BlogImage
  src="https://media.geeksforgeeks.org/wp-content/uploads/20190721025744/Screenshot-2019-07-21-at-2.57.13-AM.png"
  alt="Picture of max pooling layer"
  caption="Fig 2 - A max pooling layer layer"
  source="https://www.geeksforgeeks.org/cnn-introduction-to-pooling-layer/#"
/>

Both of these layers specialize in **feature extraction** - essentially taking what might be important for the network while
dropping most of the non-important details. Both of these layers spit out a smaller image than the one that came in. \
\
The other layer is the standard layer - the one with the nodes and weights. Each node in layer (n + 1) will compute the result:

<LatexWrapper content="z={v}\cdot{w}+b" />

Variables:

<BlogList>
  <li>**z** is the resulting vector</li>
  <li>**v** is the vector of input values of each node in the last layer</li>
  <li>**w** is the vector of weights of each node in the last layer</li>
  <li>
    **b** is the "bias" - a linear transformation that moves the function up or
    down in value
  </li>
</BlogList>

<br />

So far, all of the calculations in the dense layer have been linear. In order to make this a "neural network"
(and not a linear regression model), we need a non-linear function to pass the process through. This is known as
an **activation function**. In my code, I use two activation functions - the rectified linear unit (ReLU) function
and the sigmoid function.

<br />
ReLU:
<LatexWrapper content="f(x) = max(0, x)" />

Sigmoid:

<LatexWrapper content="f(x) = \frac{1}{1+e^{-x}}" width="200px" />

This all culminates into one number: our output value. In my code, I have suggested that "0" is a cat
and "1" is a car. Of course, you can have a neural network with multiple outputs - you just have to know
how to use them appropriately. \
\
Now...remember when I said that neural network can optimize itself through **backward propagation**?
Yeah...that math is a little trickier. \
\
Let's start with the dense layer - the basic layer. First, we used a **loss function** - a function
that gives an absolute measure of difference between the expected answer and the neural network's answer. One
of the examples of a loss function would be mean squared error, as shown in the equation below.
y is the neural network's answer, and yhat is the expected answer.

<LatexWrapper content="MSE_i=(y_i-\hat{y_i})^2" />

We then take the average of all of these losses for our training set (**n** items). Let's call that **C**.

<LatexWrapper
  width="300px"
  content="C=\frac{1}{n}\sum_{i=1}^{n}{(y_i-\hat{y_i})^2}"
/>

**Note: this is not the loss function that I used. This will be briefly touched upon in the coding section.**

Using this average loss, we can use **gradients** to find the amount by which we should change our values.
The basic objective of the gradient in this topic is to find the **minimum value of C - our loss function**.
To do this, we will express the change in **C** with respect to each weight using the chain rule.

<LatexWrapper
  width="400px"
  content="\frac{\delta{C}}{\delta{w_i}}=\frac{\delta{C}}{\delta{w_i}}*\frac{\delta{\hat{y}}}{\delta{z}}*\frac{\delta{z}}{\delta{w_i}}"
/>

Using multivariable calculus, you can solve the three gradients respectively (I am not going through it, but here is a <a href="https://towardsdatascience.com/introduction-to-math-behind-neural-networks-e8b60dbbdeba" target="_blank">cool guide on Medium</a> - it basically explains all of what I should be explaining).
After getting these three gradients, you simply change the weights and biases by their respective gradients multiplied to a learning rate Î±.
The reason we multiply the gradient by a learning rate is to make sure that we don't overstep the minimum that we want to find. \
\
Now...for the convolutional and pooling layers, there is a back propagation function for each of these layers as well.
However, I am not going to go through them as they require a vast amount of linear algebra knowledge (and ngl...I'm currently
too lazy to type it all out with LaTeX). If you are interested,

<a
  href="https://towardsdatascience.com/gentle-dive-into-math-behind-convolutional-neural-networks-79a07dd44cf9"
  target="_blank"
>
  here
</a>
is an amazing article in which all of the desired material is covered. \ \
Now...let's get into the coding!
<br />
## The Coding I used Python (specifically Keras) to build this model. The
datasets were taken from the following sources:

<br />

<BlogList>
  <li>
    <a
      href="https://images.cv/dataset/cat-image-classification-dataset"
      target="_blank"
    >
      Cat image dataset
    </a>
  </li>
  <li>
    <a
      href="https://images.cv/dataset/car-image-classification-dataset"
      target="_blank"
    >
      Car image dataset
    </a>
  </li>
</BlogList>

<br />

I started by cleaning up these files. While there were many folders containing different breeds of cats and cars
(for other purposes, perhaps), I only took the folders that said "cat" and "car" as I had no need to separate different
types of each class. I put all the images into two folders: "data/cats" and "data/cars".\
\
Since the files were randomly named with a bunch of uppercase letters, I wanted to format them. I ran this block of code
to change the file names to "cat_1", "cat_2", "cat_3", etc, etc...

<BlogCode language="python">
{`
import os
from tqdm import tqdm

# rename all files to appropriate names

cat_files = os.listdir('data/cats')

# loop through all files and use progress bar

cat_counter = 0
for file in tqdm(cat_files):
if file[:3] == "cat": continue # get the extension of the file
extension = file.split('.')[-1] # rename the file
os.rename(f'data/cats/{file}', f'data/cats/cat_{cat_counter+1}.{extension}')
cat_counter += 1

car_files = os.listdir('data/cars')

car_counter = 0
for file in tqdm(car_files):
if file[:3] == "car": continue
extension = file.split('.')[-1]
os.rename(f'data/cars/{file}', f'data/cars/car_{car_counter+1}.{extension}')
car_counter += 1
`}

</BlogCode>

The tqdm library is not essential, but it gives you a cool loading bar, so...yeah. \
\
Next, I wanted to split my dataset into training and testing data. The training data will do all the fancy
math that was mentioned earlier, while the testing data will measure how accurate the neural network is after
training. The metrics of the model's test results will be plotted (as seen later).

<BlogCode language="python">
{`
# split images into training, testing and validation
import splitfolders

splitfolders.ratio('data', output='aggregated_data', seed=1337, ratio=(.85, .15))
`}

</BlogCode>

The splitfolders library made things pretty easy for me. \
\
After this, I realized that some of the images were not openable (maybe they were corrupted, idk). In
order to fix this so as to not mess up the model, I wrote a block that validated all the images in the new folder,
"aggregated_data".

<BlogCode language="python">
{`
#remove corrupted images
from struct import unpack
from tqdm import tqdm
import os

marker_mapping = {
0xffd8: "Start of Image",
0xffe0: "Application Default Header",
0xffdb: "Quantization Table",
0xffc0: "Start of Frame",
0xffc4: "Define Huffman Table",
0xffda: "Start of Scan",
0xffd9: "End of Image"
}

class JPEG:
def __init__(self, image_file):
with open(image_file, 'rb') as f:
self.img_data = f.read()

    def decode(self):
        data = self.img_data
        while(True):
            marker, = unpack(">H", data[0:2])
            # print(marker_mapping.get(marker))
            if marker == 0xffd8:
                data = data[2:]
            elif marker == 0xffd9:
                return
            elif marker == 0xffda:
                data = data[-2:]
            else:
                lenchunk, = unpack(">H", data[2:4])
                data = data[2+lenchunk:]
            if len(data)==0:
                break

# loop through all files and use progress bar

for folder in ['aggregated_data/train/cats', 'aggregated_data/train/cars', 'aggregated_data/val/cats', 'aggregated_data/val/cars']:
files = os.listdir(folder)
for file in tqdm(files):
image = JPEG(f'{folder}/{file}')
try:
image.decode()
except:
os.remove(f'{folder}/{file}')
`}

</BlogCode>

Now, we get to the more fun part: the model itself!

<BlogCode language="python">
{`
import sys
from matplotlib import pyplot
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from keras.layers import Rescaling
from keras.optimizers import SGD
from keras.utils import image_dataset_from_directory

IMG_SIZE = 32

def cnn_model(): # define model
model = Sequential()
model.add(Rescaling(1./255, input_shape=(IMG_SIZE, IMG_SIZE, 3)))
model.add(Conv2D(IMG_SIZE, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(IMG_SIZE, IMG_SIZE, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
model.add(Dense(1, activation='sigmoid')) # compile model
opt = SGD(learning_rate=0.001, momentum=0.9)
model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])
return model
`}

</BlogCode>

The model contains convolutional 2D layers (since we are dealing with 2D images) and max pooling layers. The flattening
layer is simply a layer that flattens layer data (in this case, our feature extracted image) into a 1D array.
Interpreting this code requires a little bit of knowledge in Keras, but it should mostly make sense. The "kernel_initializer"
determines the kernel - the sliding matrix that multiplies along the image. The loss function was the rescaling layer rescales
the image to a 32x32 image. More on that later. \
\
The loss function that I used - as mentioned earlier - was not mean squared error since my neural network's output was binary (within 0 or 1).
Because of this, I used the binary crossentropy loss function. This loss function is a bit more complicated, but

<a
  href="https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a"
  target="_blank"
>
  here
</a>
is a beautiful mathematical analysis! This model architecture uses what's known
as one VGG block (3x3 convolutional + 2x2 max pooling). 
<a href="https://d2l.ai/chapter_convolutional-modern/vgg.html" target="_blank">Here is an article </a> with more information on that. \ \ Finally, I made the function that would
train and test this model.

<BlogCode language="python">
{`
def run_test_harness():
    # define model
    model = cnn_model()

    # prepare iterators
    train_it = image_dataset_from_directory(os.path.join("aggregated_data","train"),
        labels='inferred', label_mode='binary', class_names=['cars', 'cats'], color_mode='rgb', batch_size=64, image_size=(IMG_SIZE, IMG_SIZE))

    test_it = image_dataset_from_directory(os.path.join("aggregated_data","val"),
        labels='inferred', label_mode='binary', class_names=['cars', 'cats'], color_mode='rgb', batch_size=64, image_size=(IMG_SIZE, IMG_SIZE))


    res = model.fit(train_it, epochs=25, verbose=0, validation_data=test_it, validation_steps=len(test_it))
    _, acc = model.evaluate(test_it, steps=len(test_it), verbose=0)

    plot_acc(res)

    model.save('model1.h5')

`}

</BlogCode>

In a nutshell, I took the image datasets that I had produced earlier and created a Keras dataset. From there,
I ran the "fit" function - it just automatically does the calculations for you. After it finished, I evaluated the
model using the evaluate() function. These results are plotted, and the results are saved. The JSON version
of this model is the one that is currently deployed on my website. \
\
That's it! I ran the model and got some results. Now, let's talk about the results... \
\
Originally, I tried to rescale the images to 200px by 200px. However, upon running the model, the accuracy
was not looking too hot...

<BlogImage
  src="/blogs/cat-or-car/plot1.png"
  caption="Cross-entropy loss and accuracy of 200px by 200px model"
  alt="Cross-entropy loss and accuracy of 200px by 200px model"
/>

(The blue line is training, and the orange line is testing)

After a lot of deliberation, I figured that it was because the image convolution layers were not working efficiently.
Thus, I changed the size of the images to 64px by 64px, and lo and behold...

<BlogImage
  src="/blogs/cat-or-car/plot2.png"
  caption="(64px by 64px) Lookin a bit better!"
  alt="Cross-entropy loss and accuracy of 64px by 64px model"
/>

You can actually see the cross entropy loss! (I'm not sure what happened with the first graph) \
\
Finally, I decided to go even smaller - 32px by 32px - just to see what would happen. The results were interesting...

<BlogImage
  src="/blogs/cat-or-car/plot3.png"
  caption="(32px by 32px) Why the graph more erratic doh"
  alt="Cross-entropy loss and accuracy of 32px by 32px model"
/>

Interestingly, the testing loss and accuracy seem to fluctuate more near the beginning (implying a more volatile state),
but the results are better than that of the 64px by 64px model. This version of the model is the one that is currently deployed.

<br />

## Technical Difficulties

Man, it was extremely annoying to get Keras working on my computer. Well, to be more specific...**getting
TensorFlow to detect my GPU was hard.** However, this was mainly because...I don't know how to read. I did not realize
that `tensorflow>=2.10` is not natively supported on Windows. \
\
On top of this, tensorflowjs_converter - the library that I used to convert my model from .h5 to .json - does not
work on Windows. I don't remember how I figured this out, but it definitely took at least half an hour to troubleshoot.

<br />

## Conclusions?

Overall, this project took approximately 3 days to make. Aside from the MNIST database project, this was the first
completed project that I've done with machine learning, so I had a lot of fun applying my knowledge! \
\
Right now, this model only chooses between cat or car, so if you put something that isn't either of those...it'll take
its best guess... \
\
Once the code is a little more enriching and...not plagiarized(?)...I might push it to GitHub. \
\
I'm sorry if this blog is lacking some pieces here and there - I plan to do more technical blogs in the future,
and I plan to make them a bit more tutorial-oriented. I was too lazy to explain most of the math and coding that
I did. However, future technical blogs should be much more detailed and complete. \
\
Speaking of technical blogs...

<br />

### You have no idea how long it took me to write this blog.

In one of my next few blogs, I will go over the nightmare of trying to implement LaTeX and code markdown
in my portfolio (and all the new additions). Until then, I'll catch you guys in the next one o7 (please subscribe) \
\
Oh yeah, one more time: <a href="/projects/cat-or-car">here's the link to the project!</a>

<br />

## Project Pics

<BlogImage
  src="/blogs/cat-or-car/car.png"
  alt="Model parsing a car image"
  caption="Car parsed successfully!"
  style={{ border: "0.5rem solid" }}
/>

<BlogImage
  src="/blogs/cat-or-car/cat.png"
  alt="Model parsing a cat image"
  caption="Cat parsed successfully! (fun fact: that's my cat)"
  style={{ border: "0.5rem solid" }}
/>

<BlogImage
  src="/blogs/cat-or-car/maybe-a-cat.png"
  alt="Model parsing a image that is not a car or a cat"
  caption="Cat...parsed successfully?"
  style={{ border: "0.5rem solid" }}
/>